---
title: Best Practices for Search
description: Learn how to optimize your queries, refine search filters, and leverage advanced parameters for better performance.
canonical: paperguide.ai
---

## Optimize your query

Use short, specific queries that reflect the information you want the search engine to retrieve.

### Keep queries under 400 characters

- Use concise intent-focused text.
- Treat queries as search instructions, not prompts.
- Overlong queries return an error.

```json
{
  "detail": {
    "error": "Query is too long. Max query length is 400 characters."
  }
}
```

### Break complex tasks into sub-queries

- Split broad research tasks into multiple focused calls.
- Improves relevance and reduces noise.

<CodeGroup show-lines="true" tabs={[]}>
  ```json
  {
    "query": "Competitors of company ABC."
  }
  {
    "query": "Financial performance of company ABC."
  }
  {
    "query": "Recent developments of company ABC."
  }
  {
    "query": "Latest industry trends related to ABC."
  }
  ```

  ```json
  {
    "query": "Information regarding the history, financial performance, market positioning, recent developments, executive leadership, product offerings, customer demographics, strategic partnerships, mergers and acquisitions, regulatory challenges, competitor analysis, emerging market trends, technological advancements, and overall industry outlook for the company ABC and its key competitors within the industry."
  }
  ```
</CodeGroup>

## Optimize request parameters

Use only the parameters you need. Each one affects cost, relevance, and response size.

### max_results

- Controls number of retrieved results (default is 5).
- Set intentionally; large values reduce relevance.

<CodeGroup show-lines="true" tabs={[]}>
  ```json
  {
    "query": "Info about renewable energy technologies",
    "max_results": 10
  }
  ```

  ```json
  {
    "query": "Info about renewable energy technologies",
    "max_results": 300
  }
  ```
</CodeGroup>

### content and search_depth

- `content`: NLP-generated snippet for quick inspection.
- `search_depth=advanced`: Returns highly aligned snippets.
- Combine with `chunks_per_source` and `include_raw_content` when you need deeper retrieval.

<CodeGroup show-lines="true" tabs={[]}>
  ```json
  {
    "query": "How many countries use Monday.com?",
    "search_depth": "advanced",
    "chunks_per_source": 3,
    "include_raw_content": true
  }
  ```

  ```json
  {
    "query": "How many countries use Monday.com?",
    "search_depth": "advanced",
    "chunks_per_source": 3
  }
  ```

  ```json
  {
    "query": "How many countries use Monday.com?",
    "search_depth": "basic"
  }
  ```
</CodeGroup>

### Time filtering parameters

Use time filters when recency matters.

#### time_range

<CodeGroup show-lines="true" tabs={[]}>
  ```json
  {
    "query": "latest trends in machine learning",
    "time_range": "month"
  }
  ```

  ```json
  {
    "query": "latest trends in machine learning"
  }
  ```
</CodeGroup>

#### start_date and end_date

<CodeGroup show-lines="true" tabs={[]}>
  ```json
  {
    "query": "latest trends in machine learning",
    "start_date": "2025-01-01",
    "end_date": "2025-02-01"
  }
  ```

  ```json
  {
    "query": "latest trends in machine learning",
    "start_date": "2025-01-01"
  }
  ```
</CodeGroup>

### include_raw_content

Use for full-page extraction, but prefer a two-step process when depth matters.

1. Search for URLs.
2. Extract with the Extract API.

See the guidance in [Best Practices for the Extract API](/tavily/best-practices/extract#2-two-step-process-search-then-extract).

<CodeGroup show-lines="true" tabs={[]}>
  ```json
  {
    "query": "The impact of AI in healthcare",
    "include_raw_content": true
  }
  ```

  ```json
  {
    "query": "The impact of AI in healthcare"
  }
  ```
</CodeGroup>

### topic=news

Retrieve only news articles with `published_date` metadata.

<CodeGroup show-lines="true" tabs={[]}>
  ```json
  {
    "query": "What happened today in NY?",
    "topic": "news"
  }
  ```

  ```json
  {
    "query": "What happened today in NY?"
  }
  ```
</CodeGroup>

### auto_parameters

- Enables automatic tuning.
- Explicit settings override automatic ones.
- Defaults may select `advanced` search (2 credits).

<CodeGroup show-lines="true" tabs={[]}>
  ```json
  {
    "query": "impact of AI in education policy",
    "auto_parameters": true,
    "search_depth": "basic",
    "include_answer": true,
    "max_results": 10
  }
  ```

  ```json
  {
    "query": "impact of AI in education policy",
    "auto_parameters": true
  }
  ```
</CodeGroup>

### include_domains

Scope search to trusted domains.

<CodeGroup show-lines="true" tabs={[]}>
  ```json
  {
    "query": "What is the professional background of the CEO at Google?",
    "include_domains": ["linkedin.com/in"]
  }
  ```

  ```json
  {
    "query": "What is the professional background of the CEO at Google?"
  }
  ```
</CodeGroup>

<CodeGroup show-lines="true" tabs={[]}>
  ```json
  {
    "query": "What are the latest funding rounds for AI startups?",
    "include_domains": ["crunchbase.com", "techcrunch.com", "pitchbook.com"]
  }
  ```

  ```json
  {
    "query": "What are the latest funding rounds for AI startups?",
    "include_domains": ["example1.com", "example2.com", "example3.com"]
  }
  ```
</CodeGroup>

### exclude_domains

Filter out unwanted sources. Use sparingly.

<CodeGroup show-lines="true" tabs={[]}>
  ```json
  {
    "query": "US economy trends in 2025",
    "exclude_domains": ["espn.com", "vogue.com"]
  }
  ```

  ```json
  {
    "query": "US economy trends in 2025",
    "exclude_domains": ["forbes.com"]
  }
  ```
</CodeGroup>

<CodeGroup show-lines="true" tabs={[]}>
  ```json
  {
    "query": "US fashion trends in 2025",
    "exclude_domains": ["nytimes.com", "forbes.com", "bloomberg.com"]
  }
  ```

  ```json
  {
    "query": "US fashion trends in 2025",
    "exclude_domains": ["example1.com", "example2.com"]
  }
  ```
</CodeGroup>

### Website region controls

```json
{
  "query": "latest AI research",
  "include_domains": ["*.com"]
}
```

```json
{
  "query": "global economic trends",
  "exclude_domains": ["*.is"]
}
```

```json
{
  "query": "tech startup funding",
  "topic": "general",
  "country": "united states"
}
```

### Combining include and exclude domains

```json
{
  "query": "AI industry news",
  "include_domains": ["*.com"],
  "exclude_domains": ["example.com"]
}
```

## Asynchronous usage

Use meaningful concurrency patterns to avoid blocking and stay within rate limits.

- Reuse a single `AsyncTavilyClient`.
- Use `asyncio.gather` for parallel queries.
- Catch exceptions to keep pipelines resilient.

```python
import asyncio
from tavily import AsyncTavilyClient

tavily_client = AsyncTavilyClient("tvly-YOUR_API_KEY")

async def fetch_and_gather():
    queries = ["latest AI trends", "future of quantum computing"]
    try:
        responses = await asyncio.gather(
            *(tavily_client.search(q) for q in queries),
            return_exceptions=True
        )
        for response in responses:
            if isinstance(response, Exception):
                print(f"Search query failed: {response}")
            else:
                print(response)
    except Exception as e:
        print(f"Error during search queries: {e}")

asyncio.run(fetch_and_gather())
```

## Improve results with post-processing

Combine search metadata, regex extraction, and LLM reasoning for higher-quality filtering.

### LLM + keyword filtering

- Remove results containing unwanted terms.
- Prioritize content with key signals.
- Reduce cost by filtering before LLM use.

### Use metadata effectively

Key fields:

- `title`: quick relevance indicator.
- `raw_content`: detailed analysis; pair with Extract API when needed.
- `score`: alignment between snippet and query.
- `content`: general summary; deeper alignment in advanced mode.

You can sort by score, set thresholds, and combine metadata for ranking.

### Regex extraction

Use Python `re.search` and `re.findall` for structured extraction from `raw_content`.

Example:

```python
import re
text = "Company: Tavily, Location: New York"
match = re.search(r"Location: (\w+)", text)
if match:
    print(match.group(1))
```

```python
text = "Contact: john@example.com, support@tavily.com"
emails = re.findall(r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}", text)
print(emails)
```

<Callout kind="info">
  
Refine results by combining metadata analysis, regex extraction, and LLM reasoning. This produces more reliable and task-relevant output.

</Callout>

## Recommended integrations

Use these integrations to operationalize best practices:

- **OpenAI**: Use Tavily as a tool/function in chat completions.
- **LangChain**: Add Tavily to agents and RAG workflows.
- **LlamaIndex**: Merge fresh web results into index-based pipelines.

Links:

- [OpenAI integration](/tavily/integrations/openai)
- [LangChain integration](/tavily/integrations/langchain)
- [LlamaIndex integration](/tavily/integrations/llamaindex)